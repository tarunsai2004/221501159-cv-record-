{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3T1S67ZRBLn",
        "outputId": "667a7902-3009-4b28-e1fc-b1c329acee6f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 22.2MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 599kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 5.58MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.35MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0/50] [Batch 0/938] D_loss: 0.7158, G_loss: 0.6988\n",
            "[Epoch 0/50] [Batch 200/938] D_loss: 0.5531, G_loss: 0.9756\n",
            "[Epoch 0/50] [Batch 400/938] D_loss: 0.2775, G_loss: 2.4450\n",
            "[Epoch 0/50] [Batch 600/938] D_loss: 0.3429, G_loss: 1.2322\n",
            "[Epoch 0/50] [Batch 800/938] D_loss: 0.2557, G_loss: 2.9511\n",
            "[Epoch 1/50] [Batch 0/938] D_loss: 0.2903, G_loss: 1.3386\n",
            "[Epoch 1/50] [Batch 200/938] D_loss: 0.3871, G_loss: 5.5600\n",
            "[Epoch 1/50] [Batch 400/938] D_loss: 0.3403, G_loss: 4.7022\n",
            "[Epoch 1/50] [Batch 600/938] D_loss: 0.1164, G_loss: 3.6703\n",
            "[Epoch 1/50] [Batch 800/938] D_loss: 0.1262, G_loss: 3.4077\n",
            "[Epoch 2/50] [Batch 0/938] D_loss: 0.1610, G_loss: 4.0698\n",
            "[Epoch 2/50] [Batch 200/938] D_loss: 0.1335, G_loss: 2.9015\n",
            "[Epoch 2/50] [Batch 400/938] D_loss: 0.0550, G_loss: 6.6555\n",
            "[Epoch 2/50] [Batch 600/938] D_loss: 0.1847, G_loss: 2.5013\n",
            "[Epoch 2/50] [Batch 800/938] D_loss: 0.1601, G_loss: 4.0004\n",
            "[Epoch 3/50] [Batch 0/938] D_loss: 0.0989, G_loss: 5.0322\n",
            "[Epoch 3/50] [Batch 200/938] D_loss: 0.3450, G_loss: 7.6222\n",
            "[Epoch 3/50] [Batch 400/938] D_loss: 0.1638, G_loss: 2.9868\n",
            "[Epoch 3/50] [Batch 600/938] D_loss: 0.2952, G_loss: 6.5532\n",
            "[Epoch 3/50] [Batch 800/938] D_loss: 0.1358, G_loss: 3.9675\n",
            "[Epoch 4/50] [Batch 0/938] D_loss: 0.1699, G_loss: 6.9122\n",
            "[Epoch 4/50] [Batch 200/938] D_loss: 1.0160, G_loss: 0.9823\n",
            "[Epoch 4/50] [Batch 400/938] D_loss: 0.1013, G_loss: 3.6144\n",
            "[Epoch 4/50] [Batch 600/938] D_loss: 0.0626, G_loss: 7.1848\n",
            "[Epoch 4/50] [Batch 800/938] D_loss: 0.0159, G_loss: 5.2463\n",
            "[Epoch 5/50] [Batch 0/938] D_loss: 0.0814, G_loss: 4.5052\n",
            "[Epoch 5/50] [Batch 200/938] D_loss: 0.0906, G_loss: 3.7092\n",
            "[Epoch 5/50] [Batch 400/938] D_loss: 0.0503, G_loss: 5.0329\n",
            "[Epoch 5/50] [Batch 600/938] D_loss: 0.6108, G_loss: 2.0515\n",
            "[Epoch 5/50] [Batch 800/938] D_loss: 0.0350, G_loss: 2.9808\n",
            "[Epoch 6/50] [Batch 0/938] D_loss: 0.0734, G_loss: 2.5307\n",
            "[Epoch 6/50] [Batch 200/938] D_loss: 0.9375, G_loss: 5.3936\n",
            "[Epoch 6/50] [Batch 400/938] D_loss: 0.2034, G_loss: 2.8960\n",
            "[Epoch 6/50] [Batch 600/938] D_loss: 0.1564, G_loss: 2.4776\n",
            "[Epoch 6/50] [Batch 800/938] D_loss: 0.2380, G_loss: 4.8753\n",
            "[Epoch 7/50] [Batch 0/938] D_loss: 0.1567, G_loss: 2.0991\n",
            "[Epoch 7/50] [Batch 200/938] D_loss: 0.1989, G_loss: 3.1051\n",
            "[Epoch 7/50] [Batch 400/938] D_loss: 0.2523, G_loss: 1.1309\n",
            "[Epoch 7/50] [Batch 600/938] D_loss: 0.1836, G_loss: 2.3485\n",
            "[Epoch 7/50] [Batch 800/938] D_loss: 0.2569, G_loss: 1.7105\n",
            "[Epoch 8/50] [Batch 0/938] D_loss: 0.4263, G_loss: 7.6739\n",
            "[Epoch 8/50] [Batch 200/938] D_loss: 0.1375, G_loss: 2.6752\n",
            "[Epoch 8/50] [Batch 400/938] D_loss: 0.2711, G_loss: 2.3546\n",
            "[Epoch 8/50] [Batch 600/938] D_loss: 0.1089, G_loss: 2.9968\n",
            "[Epoch 8/50] [Batch 800/938] D_loss: 0.2021, G_loss: 1.8191\n",
            "[Epoch 9/50] [Batch 0/938] D_loss: 0.1938, G_loss: 3.1487\n",
            "[Epoch 9/50] [Batch 200/938] D_loss: 0.2149, G_loss: 2.4336\n",
            "[Epoch 9/50] [Batch 400/938] D_loss: 0.4848, G_loss: 4.4544\n",
            "[Epoch 9/50] [Batch 600/938] D_loss: 0.2486, G_loss: 2.7535\n",
            "[Epoch 9/50] [Batch 800/938] D_loss: 0.2807, G_loss: 1.4768\n",
            "[Epoch 10/50] [Batch 0/938] D_loss: 0.2730, G_loss: 2.1049\n",
            "[Epoch 10/50] [Batch 200/938] D_loss: 0.2074, G_loss: 2.1908\n",
            "[Epoch 10/50] [Batch 400/938] D_loss: 0.1918, G_loss: 2.6537\n",
            "[Epoch 10/50] [Batch 600/938] D_loss: 0.3478, G_loss: 4.8673\n",
            "[Epoch 10/50] [Batch 800/938] D_loss: 0.1820, G_loss: 2.7488\n",
            "[Epoch 11/50] [Batch 0/938] D_loss: 0.2902, G_loss: 3.4843\n",
            "[Epoch 11/50] [Batch 200/938] D_loss: 0.1198, G_loss: 4.0780\n",
            "[Epoch 11/50] [Batch 400/938] D_loss: 0.1523, G_loss: 3.1110\n",
            "[Epoch 11/50] [Batch 600/938] D_loss: 0.1596, G_loss: 1.8850\n",
            "[Epoch 11/50] [Batch 800/938] D_loss: 0.2051, G_loss: 3.8633\n",
            "[Epoch 12/50] [Batch 0/938] D_loss: 0.4049, G_loss: 3.7349\n",
            "[Epoch 12/50] [Batch 200/938] D_loss: 0.2720, G_loss: 3.7681\n",
            "[Epoch 12/50] [Batch 400/938] D_loss: 0.1791, G_loss: 2.8204\n",
            "[Epoch 12/50] [Batch 600/938] D_loss: 0.3325, G_loss: 2.7580\n",
            "[Epoch 12/50] [Batch 800/938] D_loss: 0.4671, G_loss: 4.8675\n",
            "[Epoch 13/50] [Batch 0/938] D_loss: 0.3225, G_loss: 4.9177\n",
            "[Epoch 13/50] [Batch 200/938] D_loss: 0.2718, G_loss: 1.9592\n",
            "[Epoch 13/50] [Batch 400/938] D_loss: 0.4486, G_loss: 1.9326\n",
            "[Epoch 13/50] [Batch 600/938] D_loss: 0.1636, G_loss: 3.1890\n",
            "[Epoch 13/50] [Batch 800/938] D_loss: 0.4394, G_loss: 2.4249\n",
            "[Epoch 14/50] [Batch 0/938] D_loss: 0.2459, G_loss: 1.2013\n",
            "[Epoch 14/50] [Batch 200/938] D_loss: 0.2103, G_loss: 4.4256\n",
            "[Epoch 14/50] [Batch 400/938] D_loss: 0.0033, G_loss: 13.6077\n",
            "[Epoch 14/50] [Batch 600/938] D_loss: 0.1895, G_loss: 6.4828\n",
            "[Epoch 14/50] [Batch 800/938] D_loss: 0.2198, G_loss: 2.9226\n",
            "[Epoch 15/50] [Batch 0/938] D_loss: 0.4800, G_loss: 4.2781\n",
            "[Epoch 15/50] [Batch 200/938] D_loss: 0.3288, G_loss: 1.8859\n",
            "[Epoch 15/50] [Batch 400/938] D_loss: 0.5295, G_loss: 0.8037\n",
            "[Epoch 15/50] [Batch 600/938] D_loss: 0.2598, G_loss: 2.0535\n",
            "[Epoch 15/50] [Batch 800/938] D_loss: 0.3135, G_loss: 1.6982\n",
            "[Epoch 16/50] [Batch 0/938] D_loss: 0.4013, G_loss: 2.5000\n",
            "[Epoch 16/50] [Batch 200/938] D_loss: 0.3335, G_loss: 2.2403\n",
            "[Epoch 16/50] [Batch 400/938] D_loss: 0.3258, G_loss: 2.6896\n",
            "[Epoch 16/50] [Batch 600/938] D_loss: 0.2469, G_loss: 2.7781\n",
            "[Epoch 16/50] [Batch 800/938] D_loss: 0.3102, G_loss: 2.2634\n",
            "[Epoch 17/50] [Batch 0/938] D_loss: 0.3579, G_loss: 1.6473\n",
            "[Epoch 17/50] [Batch 200/938] D_loss: 0.4238, G_loss: 1.8304\n",
            "[Epoch 17/50] [Batch 400/938] D_loss: 0.3355, G_loss: 1.7211\n",
            "[Epoch 17/50] [Batch 600/938] D_loss: 0.2824, G_loss: 1.5230\n",
            "[Epoch 17/50] [Batch 800/938] D_loss: 0.3068, G_loss: 1.7493\n",
            "[Epoch 18/50] [Batch 0/938] D_loss: 0.3341, G_loss: 2.2503\n",
            "[Epoch 18/50] [Batch 200/938] D_loss: 0.3220, G_loss: 1.4427\n",
            "[Epoch 18/50] [Batch 400/938] D_loss: 0.3575, G_loss: 2.6699\n",
            "[Epoch 18/50] [Batch 600/938] D_loss: 0.2907, G_loss: 1.6321\n",
            "[Epoch 18/50] [Batch 800/938] D_loss: 0.3716, G_loss: 2.5735\n",
            "[Epoch 19/50] [Batch 0/938] D_loss: 0.9094, G_loss: 2.9775\n",
            "[Epoch 19/50] [Batch 200/938] D_loss: 0.4016, G_loss: 1.5394\n",
            "[Epoch 19/50] [Batch 400/938] D_loss: 0.7443, G_loss: 0.7907\n",
            "[Epoch 19/50] [Batch 600/938] D_loss: 0.5443, G_loss: 2.3084\n",
            "[Epoch 19/50] [Batch 800/938] D_loss: 0.3255, G_loss: 2.0283\n",
            "[Epoch 20/50] [Batch 0/938] D_loss: 0.3612, G_loss: 1.7119\n",
            "[Epoch 20/50] [Batch 200/938] D_loss: 0.4496, G_loss: 1.3300\n",
            "[Epoch 20/50] [Batch 400/938] D_loss: 0.4500, G_loss: 1.8214\n",
            "[Epoch 20/50] [Batch 600/938] D_loss: 0.4038, G_loss: 1.9509\n",
            "[Epoch 20/50] [Batch 800/938] D_loss: 0.2651, G_loss: 1.9525\n",
            "[Epoch 21/50] [Batch 0/938] D_loss: 0.4439, G_loss: 1.2895\n",
            "[Epoch 21/50] [Batch 200/938] D_loss: 0.3363, G_loss: 2.8901\n",
            "[Epoch 21/50] [Batch 400/938] D_loss: 0.2409, G_loss: 2.0660\n",
            "[Epoch 21/50] [Batch 600/938] D_loss: 0.3717, G_loss: 1.9121\n",
            "[Epoch 21/50] [Batch 800/938] D_loss: 0.3329, G_loss: 2.1323\n",
            "[Epoch 22/50] [Batch 0/938] D_loss: 0.3509, G_loss: 2.0690\n",
            "[Epoch 22/50] [Batch 200/938] D_loss: 0.3476, G_loss: 1.7963\n",
            "[Epoch 22/50] [Batch 400/938] D_loss: 0.3436, G_loss: 1.2383\n",
            "[Epoch 22/50] [Batch 600/938] D_loss: 0.4402, G_loss: 1.4279\n",
            "[Epoch 22/50] [Batch 800/938] D_loss: 0.3897, G_loss: 2.0198\n",
            "[Epoch 23/50] [Batch 0/938] D_loss: 0.3687, G_loss: 1.4928\n",
            "[Epoch 23/50] [Batch 200/938] D_loss: 0.3682, G_loss: 2.1427\n",
            "[Epoch 23/50] [Batch 400/938] D_loss: 0.5285, G_loss: 2.7885\n",
            "[Epoch 23/50] [Batch 600/938] D_loss: 0.4387, G_loss: 1.2228\n",
            "[Epoch 23/50] [Batch 800/938] D_loss: 0.3853, G_loss: 1.7005\n",
            "[Epoch 24/50] [Batch 0/938] D_loss: 0.3270, G_loss: 1.4855\n",
            "[Epoch 24/50] [Batch 200/938] D_loss: 0.4973, G_loss: 1.8057\n",
            "[Epoch 24/50] [Batch 400/938] D_loss: 0.3306, G_loss: 2.2908\n",
            "[Epoch 24/50] [Batch 600/938] D_loss: 0.3795, G_loss: 1.3211\n",
            "[Epoch 24/50] [Batch 800/938] D_loss: 0.4000, G_loss: 1.2340\n",
            "[Epoch 25/50] [Batch 0/938] D_loss: 0.4867, G_loss: 1.1171\n",
            "[Epoch 25/50] [Batch 200/938] D_loss: 0.4862, G_loss: 2.8556\n",
            "[Epoch 25/50] [Batch 400/938] D_loss: 0.4374, G_loss: 1.3534\n",
            "[Epoch 25/50] [Batch 600/938] D_loss: 0.3709, G_loss: 1.7095\n",
            "[Epoch 25/50] [Batch 800/938] D_loss: 0.3931, G_loss: 1.6432\n",
            "[Epoch 26/50] [Batch 0/938] D_loss: 0.4001, G_loss: 1.4169\n",
            "[Epoch 26/50] [Batch 200/938] D_loss: 0.4708, G_loss: 2.5913\n",
            "[Epoch 26/50] [Batch 400/938] D_loss: 0.4349, G_loss: 1.6263\n",
            "[Epoch 26/50] [Batch 600/938] D_loss: 0.3976, G_loss: 1.5097\n",
            "[Epoch 26/50] [Batch 800/938] D_loss: 0.4141, G_loss: 1.0016\n",
            "[Epoch 27/50] [Batch 0/938] D_loss: 0.3832, G_loss: 1.4547\n",
            "[Epoch 27/50] [Batch 200/938] D_loss: 0.4045, G_loss: 1.2371\n",
            "[Epoch 27/50] [Batch 400/938] D_loss: 0.4675, G_loss: 1.5932\n",
            "[Epoch 27/50] [Batch 600/938] D_loss: 0.3941, G_loss: 1.3524\n",
            "[Epoch 27/50] [Batch 800/938] D_loss: 0.4884, G_loss: 2.7043\n",
            "[Epoch 28/50] [Batch 0/938] D_loss: 0.3891, G_loss: 1.4341\n",
            "[Epoch 28/50] [Batch 200/938] D_loss: 0.4253, G_loss: 2.0198\n",
            "[Epoch 28/50] [Batch 400/938] D_loss: 0.4012, G_loss: 1.9124\n",
            "[Epoch 28/50] [Batch 600/938] D_loss: 0.4709, G_loss: 1.9687\n",
            "[Epoch 28/50] [Batch 800/938] D_loss: 0.5248, G_loss: 2.3727\n",
            "[Epoch 29/50] [Batch 0/938] D_loss: 0.3596, G_loss: 1.4223\n",
            "[Epoch 29/50] [Batch 200/938] D_loss: 0.3957, G_loss: 2.2704\n",
            "[Epoch 29/50] [Batch 400/938] D_loss: 0.4598, G_loss: 2.6776\n",
            "[Epoch 29/50] [Batch 600/938] D_loss: 0.3661, G_loss: 1.3895\n",
            "[Epoch 29/50] [Batch 800/938] D_loss: 0.4913, G_loss: 2.1533\n",
            "[Epoch 30/50] [Batch 0/938] D_loss: 0.4655, G_loss: 2.1211\n",
            "[Epoch 30/50] [Batch 200/938] D_loss: 0.4165, G_loss: 1.2336\n",
            "[Epoch 30/50] [Batch 400/938] D_loss: 0.3130, G_loss: 2.1747\n",
            "[Epoch 30/50] [Batch 600/938] D_loss: 0.3738, G_loss: 1.3795\n",
            "[Epoch 30/50] [Batch 800/938] D_loss: 0.4985, G_loss: 0.6866\n",
            "[Epoch 31/50] [Batch 0/938] D_loss: 0.5067, G_loss: 0.7636\n",
            "[Epoch 31/50] [Batch 200/938] D_loss: 0.3758, G_loss: 1.5145\n",
            "[Epoch 31/50] [Batch 400/938] D_loss: 0.3482, G_loss: 2.0258\n",
            "[Epoch 31/50] [Batch 600/938] D_loss: 0.4280, G_loss: 1.4946\n",
            "[Epoch 31/50] [Batch 800/938] D_loss: 0.4131, G_loss: 1.7607\n",
            "[Epoch 32/50] [Batch 0/938] D_loss: 0.4525, G_loss: 1.6840\n",
            "[Epoch 32/50] [Batch 200/938] D_loss: 0.4369, G_loss: 1.0810\n",
            "[Epoch 32/50] [Batch 400/938] D_loss: 0.4373, G_loss: 1.5956\n",
            "[Epoch 32/50] [Batch 600/938] D_loss: 0.3522, G_loss: 1.3388\n",
            "[Epoch 32/50] [Batch 800/938] D_loss: 0.3636, G_loss: 1.4726\n",
            "[Epoch 33/50] [Batch 0/938] D_loss: 0.3784, G_loss: 1.5850\n",
            "[Epoch 33/50] [Batch 200/938] D_loss: 0.5309, G_loss: 2.6611\n",
            "[Epoch 33/50] [Batch 400/938] D_loss: 0.3954, G_loss: 2.1877\n",
            "[Epoch 33/50] [Batch 600/938] D_loss: 0.4661, G_loss: 1.0739\n",
            "[Epoch 33/50] [Batch 800/938] D_loss: 0.3580, G_loss: 1.6512\n",
            "[Epoch 34/50] [Batch 0/938] D_loss: 0.4401, G_loss: 2.4667\n",
            "[Epoch 34/50] [Batch 200/938] D_loss: 0.4053, G_loss: 1.0892\n",
            "[Epoch 34/50] [Batch 400/938] D_loss: 0.3707, G_loss: 2.1670\n",
            "[Epoch 34/50] [Batch 600/938] D_loss: 0.3879, G_loss: 1.1486\n",
            "[Epoch 34/50] [Batch 800/938] D_loss: 0.4422, G_loss: 2.0477\n",
            "[Epoch 35/50] [Batch 0/938] D_loss: 0.3712, G_loss: 1.5789\n",
            "[Epoch 35/50] [Batch 200/938] D_loss: 0.3268, G_loss: 1.9424\n",
            "[Epoch 35/50] [Batch 400/938] D_loss: 0.4275, G_loss: 2.5898\n",
            "[Epoch 35/50] [Batch 600/938] D_loss: 0.4640, G_loss: 2.3077\n",
            "[Epoch 35/50] [Batch 800/938] D_loss: 0.3366, G_loss: 1.7301\n",
            "[Epoch 36/50] [Batch 0/938] D_loss: 0.4937, G_loss: 0.7846\n",
            "[Epoch 36/50] [Batch 200/938] D_loss: 0.5664, G_loss: 1.0161\n",
            "[Epoch 36/50] [Batch 400/938] D_loss: 0.4519, G_loss: 1.0000\n",
            "[Epoch 36/50] [Batch 600/938] D_loss: 0.3935, G_loss: 1.9202\n",
            "[Epoch 36/50] [Batch 800/938] D_loss: 0.4050, G_loss: 2.0812\n",
            "[Epoch 37/50] [Batch 0/938] D_loss: 0.3347, G_loss: 1.9316\n",
            "[Epoch 37/50] [Batch 200/938] D_loss: 0.3914, G_loss: 1.7886\n",
            "[Epoch 37/50] [Batch 400/938] D_loss: 0.4100, G_loss: 1.8042\n",
            "[Epoch 37/50] [Batch 600/938] D_loss: 0.3843, G_loss: 1.7175\n",
            "[Epoch 37/50] [Batch 800/938] D_loss: 0.3933, G_loss: 1.6618\n",
            "[Epoch 38/50] [Batch 0/938] D_loss: 0.5454, G_loss: 0.9996\n",
            "[Epoch 38/50] [Batch 200/938] D_loss: 0.3254, G_loss: 1.8805\n",
            "[Epoch 38/50] [Batch 400/938] D_loss: 0.4859, G_loss: 1.2847\n",
            "[Epoch 38/50] [Batch 600/938] D_loss: 0.4266, G_loss: 1.5043\n",
            "[Epoch 38/50] [Batch 800/938] D_loss: 0.3734, G_loss: 2.3519\n",
            "[Epoch 39/50] [Batch 0/938] D_loss: 0.3896, G_loss: 1.6680\n",
            "[Epoch 39/50] [Batch 200/938] D_loss: 0.3684, G_loss: 1.6478\n",
            "[Epoch 39/50] [Batch 400/938] D_loss: 0.3612, G_loss: 1.8744\n",
            "[Epoch 39/50] [Batch 600/938] D_loss: 0.4397, G_loss: 1.2795\n",
            "[Epoch 39/50] [Batch 800/938] D_loss: 0.3995, G_loss: 1.0559\n",
            "[Epoch 40/50] [Batch 0/938] D_loss: 0.4098, G_loss: 2.0990\n",
            "[Epoch 40/50] [Batch 200/938] D_loss: 0.3763, G_loss: 1.6742\n",
            "[Epoch 40/50] [Batch 400/938] D_loss: 0.3656, G_loss: 1.8305\n",
            "[Epoch 40/50] [Batch 600/938] D_loss: 0.4158, G_loss: 1.9510\n",
            "[Epoch 40/50] [Batch 800/938] D_loss: 0.3989, G_loss: 1.6610\n",
            "[Epoch 41/50] [Batch 0/938] D_loss: 0.3959, G_loss: 1.2813\n",
            "[Epoch 41/50] [Batch 200/938] D_loss: 0.3912, G_loss: 2.0568\n",
            "[Epoch 41/50] [Batch 400/938] D_loss: 0.4790, G_loss: 1.6194\n",
            "[Epoch 41/50] [Batch 600/938] D_loss: 0.3266, G_loss: 1.7568\n",
            "[Epoch 41/50] [Batch 800/938] D_loss: 0.4334, G_loss: 1.0272\n",
            "[Epoch 42/50] [Batch 0/938] D_loss: 0.4517, G_loss: 1.8597\n",
            "[Epoch 42/50] [Batch 200/938] D_loss: 0.3594, G_loss: 1.9847\n",
            "[Epoch 42/50] [Batch 400/938] D_loss: 0.3300, G_loss: 1.5140\n",
            "[Epoch 42/50] [Batch 600/938] D_loss: 0.4454, G_loss: 1.5105\n",
            "[Epoch 42/50] [Batch 800/938] D_loss: 0.4069, G_loss: 1.9783\n",
            "[Epoch 43/50] [Batch 0/938] D_loss: 0.4049, G_loss: 1.3964\n",
            "[Epoch 43/50] [Batch 200/938] D_loss: 0.3999, G_loss: 2.0915\n",
            "[Epoch 43/50] [Batch 400/938] D_loss: 0.3516, G_loss: 2.2850\n",
            "[Epoch 43/50] [Batch 600/938] D_loss: 0.4222, G_loss: 2.0918\n",
            "[Epoch 43/50] [Batch 800/938] D_loss: 0.4373, G_loss: 1.4114\n",
            "[Epoch 44/50] [Batch 0/938] D_loss: 0.4060, G_loss: 1.4480\n",
            "[Epoch 44/50] [Batch 200/938] D_loss: 0.3901, G_loss: 1.2646\n",
            "[Epoch 44/50] [Batch 400/938] D_loss: 0.3094, G_loss: 2.4366\n",
            "[Epoch 44/50] [Batch 600/938] D_loss: 0.3712, G_loss: 2.2651\n",
            "[Epoch 44/50] [Batch 800/938] D_loss: 0.4198, G_loss: 1.0430\n",
            "[Epoch 45/50] [Batch 0/938] D_loss: 0.3788, G_loss: 1.4711\n",
            "[Epoch 45/50] [Batch 200/938] D_loss: 0.3865, G_loss: 1.7638\n",
            "[Epoch 45/50] [Batch 400/938] D_loss: 0.3831, G_loss: 1.9373\n",
            "[Epoch 45/50] [Batch 600/938] D_loss: 0.4141, G_loss: 1.3953\n",
            "[Epoch 45/50] [Batch 800/938] D_loss: 0.4586, G_loss: 1.1311\n",
            "[Epoch 46/50] [Batch 0/938] D_loss: 0.4030, G_loss: 2.1317\n",
            "[Epoch 46/50] [Batch 200/938] D_loss: 0.5118, G_loss: 1.4664\n",
            "[Epoch 46/50] [Batch 400/938] D_loss: 0.3309, G_loss: 1.9651\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Hyperparameters\n",
        "latent_dim = 100\n",
        "hidden_dim = 256\n",
        "image_dim = 784  # 28x28 images\n",
        "num_epochs = 50\n",
        "batch_size = 64\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])  # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, image_dim),\n",
        "            nn.Tanh()  # Output range [-1, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        return img.view(img.size(0), 1, 28, 28)\n",
        "\n",
        "# Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(image_dim, hidden_dim),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "            nn.Sigmoid()  # Output probability\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.size(0), -1)\n",
        "        validity = self.model(img_flat)\n",
        "        return validity\n",
        "\n",
        "# Initialize models\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "# Loss function\n",
        "adversarial_loss = nn.BCELoss()\n",
        "\n",
        "# Optimizers\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (imgs, _) in enumerate(train_loader):\n",
        "        batch_size = imgs.size(0)\n",
        "\n",
        "        # Ground truth labels\n",
        "        real_label = torch.ones(batch_size, 1).to(device)\n",
        "        fake_label = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "        d_optimizer.zero_grad()\n",
        "\n",
        "        # Train with real images\n",
        "        real_imgs = imgs.to(device)\n",
        "        real_validity = discriminator(real_imgs)\n",
        "        d_real_loss = adversarial_loss(real_validity, real_label)\n",
        "\n",
        "        # Train with fake images\n",
        "        z = torch.randn(batch_size, latent_dim).to(device)\n",
        "        fake_imgs = generator(z)\n",
        "        fake_validity = discriminator(fake_imgs.detach())\n",
        "        d_fake_loss = adversarial_loss(fake_validity, fake_label)\n",
        "\n",
        "        # Total discriminator loss\n",
        "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "        g_optimizer.zero_grad()\n",
        "\n",
        "        # Generate fake images and classify them\n",
        "        fake_validity = discriminator(fake_imgs)\n",
        "        g_loss = adversarial_loss(fake_validity, real_label)  # Trick discriminator\n",
        "\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "        # Print progress\n",
        "        if i % 200 == 0:\n",
        "            print(f\"[Epoch {epoch}/{num_epochs}] [Batch {i}/{len(train_loader)}] \"\n",
        "                  f\"D_loss: {d_loss.item():.4f}, G_loss: {g_loss.item():.4f}\")\n",
        "\n",
        "    # Save generated images every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "        with torch.no_grad():\n",
        "            fake_imgs = generator(torch.randn(16, latent_dim).to(device))\n",
        "            fake_imgs = fake_imgs.cpu()\n",
        "            grid = make_grid(fake_imgs, nrow=4, normalize=True)\n",
        "\n",
        "            plt.figure(figsize=(6, 6))\n",
        "            plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
        "            plt.axis('off')\n",
        "            plt.title(f'Generated Digits at Epoch {epoch}')\n",
        "            plt.savefig(f'generated_digits_epoch_{epoch}.png')\n",
        "            plt.close()\n",
        "\n",
        "# Save final generator model\n",
        "torch.save(generator.state_dict(), 'generator.pth')\n",
        "\n",
        "# Generate and display final samples\n",
        "with torch.no_grad():\n",
        "    final_samples = generator(torch.randn(16, latent_dim).to(device))\n",
        "    final_samples = final_samples.cpu()\n",
        "    grid = make_grid(final_samples, nrow=4, normalize=True)\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
        "    plt.axis('off')\n",
        "    plt.title('Final Generated Digits')\n",
        "    plt.savefig('final_generated_digits.png')\n",
        "    plt.show()"
      ]
    }
  ]
}